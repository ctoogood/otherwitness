---
 title: Lethal Autonomous Weapons & Human Rights
 subheading: The Arms Trade
 slug: /laws
 date: 2019-11-26
 featuredImage: '../images/laws.jpg'
 description: 'With such outspoken calls for a preemptive ban on the development and use of lethal autonomous weapons, what are the potential humanitarian implications of this technology?'
---

 Rapid developments in artificial intelligence mean that the creation and deployment of lethal autonomous weapons is nearing reality. These weapons would be able to select and engage their targets independently using programmed algorithms.

 With the potential to become weapons of mass destruction, there have been great efforts to impose a preemptive ban on the development and deployment of lethal autonomous weapons(LAWs). The Campaign to Stop Killer Robots, a large coalition consisting of many NGOs, human rights leaders and scientists, is the main entity calling for a such a ban. And this month Antonio Guterres, UN Secretary-General, repeated his earlier calls for an international treaty to ban lethal autonomous weapons and claimed that “machines that have the power and discretion to kill without human intervention are politically unacceptable and morally despicable.”[^1]

**With such outspoken calls for a preemptive ban on the development and use of lethal autonomous weapons, what are the potential humanitarian implications of this technology?**

# Predicted Capabilities & Usage

 Although there has not yet been an attempt to produce an internationally recognised definition of what constitutes a lethal autonomous weapon, the widely accepted term is any weapon system that has autonomy in the critical functions of selecting and attacking targets.[^2]

 Without the need for human input, weapons systems could, for instance, defend high-security areas and attack anyone who approaches. Drones could patrol the skies and attack when they see a particular target. Without restrictions for personnel required to operate the equipment(controlled drones can require large teams), such weapons could also be deployed in swarms - dozens of them simultaneously attacking their targets.  
 Tanks, drones and other vehicles seem to be the main vision for the use of this technology, with aims to improve speed(physical and decision making), accuracy, stealth and to protect the lives of soldiers. 

 Critics of this technology see the potential for catastrophic scenarios to arise from the use and availability of lethal autonomous weapons.

# Misuse & Malfunction

 Even if such a weapon could be produced with the ability to abide by humanitarian law and eliminate the potential for human failings, it’s still likely that the technology will fall into the hands of those who wish to use it with sinister intentions. In an interview in the New York Times, AI expert Toby Walsh claimed that LAWs would be: 

> **“...cheap and easy to produce. Some can be made with a 3-D printer, and they could easily fall into the hands of terrorists.”**[^3]

 If cheap and easy to produce there is huge potential for these weapons to be mass-produced and deployed in very large numbers.

 Pair this with the precision that AI has to discriminate through facial recognition technology and there’s great potential for LAWs to be used in the repression of a population, discriminatory killings or even acts of genocide.  A 2015 letter signed by over 1000 robotics and AI researchers warned  that autonomous weapons would be:

> **“ideal for tasks such as assassinations, destabilizing nations, subduing populations and selectively killing a particular ethnic group.”**[^4]

 With the ability to program a potentially mass-produced weapon to target a particular demographic, the repression and atrocities which occur currently against particular groups could be worsened and made a lot easier for those who commit these crimes.

 Even if deployed to abide by humanitarian law, the risks of this technology to malfunction or to be hacked are too high to allow robots the responsibility to decide whether a human lives or dies. Not even the highest standard of technology can be expected to perform flawlessly. And if deployed in masses, the implications of a malfunction or malicious hack could be severe.

> **“The likelihood of a disaster is in proportion to how many of these machines will be in a particular area at once. What you are looking at are possible atrocities and unlawful killings even under laws of warfare, especially if hundreds or thousands of these machines are deployed. There could be large-scale accidents because these things will start to behave in unexpected ways. Which is why any advanced weapons systems should be subject to meaningful human control, otherwise they have to be banned because they are far too unpredictable and dangerous.”** *Laura Nolan, AI Expert*[^5]

# Fuelling Conflict

 The potential ease of mass production and the reduction of risk to human soldiers could also increase the risk of conflict. Nations or non-state actors may be more willing to initiate attacks if their forces can be built rather than recruited.

 The pace of war could also be increased with the ability of machines to make decisions much faster than humans. This faster decision making would also be a temptation to allow AI to give orders on the battlefield.

> **“That could have worrying consequences. Able to think faster than humans, an AI-enabled command system might cue up missile strikes on aircraft carriers and airbases at a pace that leaves no time for diplomacy and in ways that are not fully understood by its operators.”**[^6]

# Arms Control

 The current solution proposed by the opposition to lethal autonomous weapons is a preemptive ban on their development and use. Many states are calling for an international treaty but countries such as the US, Russia, China and the UK appear to be doing their utmost to stall any meaningful dialogue on the subject. Without in-depth discussions on the topic at an international level and the introduction of a legally binding treaty before such weapons become reality, the implications of deploying lethal autonomous weapons could have wide-ranging humanitarian consequences.

# Lethal Autonomous Weapons Links

Here’s a collection of pieces of insightful journalism on the topic.

<div class="HrjLink"> <a class="hrjtitle" target="_blank" rel="noopener noreferrer" href="https://www.vox.com/2019/6/21/18691459/killer-robots-lethal-autonomous-weapons-ai-war"> <h2>Death by algorithm: the age of killer robots is closer than you think</h2> <h3>Vox</h3> </a> <img src="https://cdn.vox-cdn.com/thumbor/Nnd0bYKiCgC42cOg4XhoQYrG22c=/0x107:2770x1557/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/16388534/85545249.jpg.jpg" alt="We have the technology to make robots that kill without oversight. But should we?" /> <p>We have the technology to make robots that kill without oversight. But should we?</p> <a class="readMore" target="_blank" rel="noopener noreferrer" href="https://www.vox.com/2019/6/21/18691459/killer-robots-lethal-autonomous-weapons-ai-war">Read More</a> </div>

<div class="HrjLink"> <a class="hrjtitle" target="_blank" rel="noopener noreferrer" href="https://www.hrw.org/news/2019/11/20/ringing-alarm-killer-robots"> <h2>Ringing the Alarm on Killer Robots</h2> <h3>Human Rights Watch</h3> </a> <img src="https://www.hrw.org/sites/default/files/styles/open_graph/public/multimedia_images_2019/201911arms_robots_treatyelements_0.jpg?itok=k14NfPux" alt="Major military powers are racing to embrace weapons that select and fire on targets without meaningful human control. This is raising the specter of immoral, unaccountable, largely uncontrollable weapon systems – killer robots. It is also driving fears of widespread proliferation and arms races leading to global and regional instability." /> <p>Major military powers are racing to embrace weapons that select and fire on targets without meaningful human control. This is raising the specter of immoral, unaccountable, largely uncontrollable weapon systems – killer robots. It is also driving fears of widespread proliferation and arms races leading to global and regional instability.</p> <a class="readMore" target="_blank" rel="noopener noreferrer" href="https://www.hrw.org/news/2019/11/20/ringing-alarm-killer-robots">Read More</a> </div>

<div class="HrjLink"> <a class="hrjtitle" target="_blank" rel="noopener noreferrer" href="https://www.economist.com/leaders/2019/09/05/artificial-intelligence-and-war"> <h2>Artificial intelligence and war</h2> <h3>The Economist</h3> </a> <img src="https://www.economist.com/sites/default/files/images/print-edition/20190907_LDP002_0.jpg" alt="As computers play a bigger role in warfare, the dangers to humans rise" /> <p>As computers play a bigger role in warfare, the dangers to humans rise</p> <a class="readMore" target="_blank" rel="noopener noreferrer" href="https://www.economist.com/leaders/2019/09/05/artificial-intelligence-and-war">Read More</a> </div>

<div class="HrjLink"> <a class="hrjtitle" target="_blank" rel="noopener noreferrer" href="https://www.nytimes.com/2018/11/15/magazine/autonomous-robots-weapons.html"> <h2>Are Killer Robots the Future of War? Parsing the Facts on Autonomous Weapons</h2> <h3>NY Times</h3> </a> <img src="https://static01.nyt.com/images/2018/11/15/magazine/15atwar-robots-2/15atwar-robots-2-facebookJumbo.jpg" alt="Under what circumstances should militaries delegate the decision to take a human life to machines? It’s a moral leap that the international community is grappling with." /> <p>Under what circumstances should militaries delegate the decision to take a human life to machines? It’s a moral leap that the international community is grappling with.</p> <a class="readMore" target="_blank" rel="noopener noreferrer" href="https://www.nytimes.com/2018/11/15/magazine/autonomous-robots-weapons.html">Read More</a> </div>

<div class="HrjLink"> <a class="hrjtitle" target="_blank" rel="noopener noreferrer" href="http://www.theguardian.com/technology/2019/sep/15/ex-google-worker-fears-killer-robots-cause-mass-atrocities"> <h2>Ex-Google worker fears 'killer robots' could cause mass atrocities</h2> <h3>the Guardian</h3> </a> <img src="https://i.guim.co.uk/img/media/6d6e90b98d5437f673d6a26eacb2cf2fb5814025/124_242_3316_1990/master/3316.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2fc36aeeec49e48ceb10eed56011d684" alt="Engineer who quit over military drone project warns AI might also accidentally start a war" /> <p>Engineer who quit over military drone project warns AI might also accidentally start a war</p> <a class="readMore" target="_blank" rel="noopener noreferrer" href="http://www.theguardian.com/technology/2019/sep/15/ex-google-worker-fears-killer-robots-cause-mass-atrocities">Read More</a> </div>

<div class="HrjLink"> <a class="hrjtitle" target="_blank" rel="noopener noreferrer" href="https://www.nytimes.com/2019/07/30/science/autonomous-weapons-artificial-intelligence.html"> <h2>Toby Walsh, A.I. Expert, Is Racing to Stop the Killer Robots</h2> <h3>NY Times</h3> </a> <img src="https://static01.nyt.com/images/2019/07/30/science/26SCI-CONVERSATION1/26SCI-CONVERSATION1-facebookJumbo.jpg" alt="Autonomous weapons, capable of acting without human oversight, are closer than we think, Dr. Walsh believes, and must be banned." /> <p>Autonomous weapons, capable of acting without human oversight, are closer than we think, Dr. Walsh believes, and must be banned.</p> <a class="readMore" target="_blank" rel="noopener noreferrer" href="https://www.nytimes.com/2019/07/30/science/autonomous-weapons-artificial-intelligence.html">Read More</a> </div>

<div class="HrjLink"> <a class="hrjtitle" target="_blank" rel="noopener noreferrer" href="https://www.cbc.ca/radio/ideas/killer-robots-march-into-uncharted-ethical-territory-1.5289804"> <h2>Killer robots march into uncharted ethical territory | CBC Radio</h2> <h3>CBC</h3> </a> <img src="https://i.cbc.ca/1.5289848.1568990748!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_620/warning-about-autonomous-weapons.jpg" alt="What happens if autonomous weapons fight our wars? What if they select and kill targets without any human intervention? The world is closer to this scenario than ever before. But there's no consensus on whether — or even how — it would ever be ethical. This episode delves into the complex conundrums of robot warfare." /> <p>What happens if autonomous weapons fight our wars? What if they select and kill targets without any human intervention? The world is closer to this scenario than ever before. But there's no consensus on whether — or even how — it would ever be ethical. This episode delves into the complex conundrums of robot warfare.</p> <a class="readMore" target="_blank" rel="noopener noreferrer" href="https://www.cbc.ca/radio/ideas/killer-robots-march-into-uncharted-ethical-territory-1.5289804">Read More</a> </div>



[^1]: https://www.hrw.org/news/2019/11/20/ringing-alarm-killer-robots

[^2]: https://www.icrc.org/en/document/autonomous-weapon-systems-under-international-humanitarian-law

[^3]: https://www.nytimes.com/2019/07/30/science/autonomous-weapons-artificial-intelligence.html

[^4]: https://www.nytimes.com/2018/11/15/magazine/autonomous-robots-weapons.html

[^5]: http://www.theguardian.com/technology/2019/sep/15/ex-google-worker-fears-killer-robots-cause-mass-atrocities

[^6]: https://www.economist.com/leaders/2019/09/05/artificial-intelligence-and-war